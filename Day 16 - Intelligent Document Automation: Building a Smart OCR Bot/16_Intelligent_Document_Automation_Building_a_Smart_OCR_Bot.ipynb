{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent document processing\n",
        "\n",
        "Helps in processign unstructured and semi-structured data in documents."
      ],
      "metadata": {
        "id": "-CSDkcmvSSMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing purposes - we will be using only a small set (5) of resumes.\n",
        "\n",
        "Resumes were obtained from: [Kaggle](https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset)"
      ],
      "metadata": {
        "id": "LvfjWLjnhnKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and processing functions:"
      ],
      "metadata": {
        "id": "YitMhpPbzXtP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0HEZWYgdR4Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b27b91-8e90-442c-c012-e47a91da33b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: poppler-utils in /usr/local/lib/python3.12/dist-packages (0.1.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.12/dist-packages (from poppler-utils) (8.2.1)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "! pip install opencv-python matplotlib numpy pdf2image\n",
        "! pip install poppler-utils\n",
        "! pip install pytesseract pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "irziWzNQvXpH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(image, title=\"Image\"):\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yU6NIO5Fvi5Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to grayscale\n",
        "def convert_to_grayscale(image):\n",
        "  return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def reduce_noise(gray_image):\n",
        "  return cv2.GaussianBlur(gray_image, (5, 5), 0)"
      ],
      "metadata": {
        "id": "5v6jXn-cv1p1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize_image(blur_reduced_image):\n",
        "  return cv2.adaptiveThreshold(\n",
        "    blur_reduced_image,\n",
        "    255,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "    cv2.THRESH_BINARY_INV, # Invert the colors (text becomes white)\n",
        "    11, # Block size\n",
        "    4  # Constant C\n",
        "  )"
      ],
      "metadata": {
        "id": "rgtpAOIFv3uI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deskew_image(image):\n",
        "    \"\"\"\n",
        "    Corrects the skew of an image by finding the minimum area rectangle\n",
        "    of the text block and rotating accordingly.\n",
        "    \"\"\"\n",
        "    # Find all non-zero (white) pixels\n",
        "    coords = cv2.findNonZero(image)\n",
        "\n",
        "    # Get the minimum area bounding rectangle\n",
        "    # It returns (center(x,y), (width, height), angle of rotation)\n",
        "    rect = cv2.minAreaRect(coords)\n",
        "    angle = rect[-1] - 90\n",
        "\n",
        "    # The `cv2.minAreaRect` angle has a specific range.\n",
        "    # We need to adjust it for our rotation.\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = angle\n",
        "\n",
        "    # Get the rotation matrix and rotate the image\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h),\n",
        "                             flags=cv2.INTER_CUBIC,\n",
        "                             borderMode=cv2.BORDER_REPLICATE)\n",
        "    print(f\"Detected skew angle: {angle:.2f} degrees\")\n",
        "\n",
        "    # Now, rotate the original grayscale image by the same angle\n",
        "    (h, w) = rotated.shape\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    deskewed_gray = cv2.warpAffine(rotated, M, (w, h),\n",
        "                                  flags=cv2.INTER_CUBIC,\n",
        "                                  borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    return deskewed_gray"
      ],
      "metadata": {
        "id": "a_0OWuTLv5wg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_one_image(image):\n",
        "  image = convert_to_grayscale(image)\n",
        "  print(\"Converted image to grayscale..\")\n",
        "  image = reduce_noise(image)\n",
        "  print(\"Reduced noise in the image..\")\n",
        "  image = binarize_image(image)\n",
        "  print(\"Binarized the image..\")\n",
        "  image = deskew_image(image)\n",
        "  print(\"Corrected image orientation..\")\n",
        "  return image"
      ],
      "metadata": {
        "id": "EcHux5Fgv6k3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepping the resumes for extraction:"
      ],
      "metadata": {
        "id": "uyLbWt9UwG8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "output_folder_path = \"/content/processed_images\"\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "resumes_folder = '/content/Resumes'\n",
        "\n",
        "for resume_name in os.listdir(resumes_folder):\n",
        "  if resume_name.endswith('.pdf'):\n",
        "    print(f\"Processing resume: {resume_name}\")\n",
        "    resume_path = os.path.join(resumes_folder, resume_name)\n",
        "\n",
        "    # Convert the first page of the PDF to an image\n",
        "    try:\n",
        "      pages = convert_from_path(resume_path, first_page=1, last_page=1)\n",
        "      if pages:\n",
        "        image = cv2.cvtColor(np.array(pages[0]), cv2.COLOR_RGB2BGR)\n",
        "        processed_image = process_one_image(image)\n",
        "        output_path = os.path.join(output_folder_path, resume_name.replace('.pdf', '.png'))\n",
        "        cv2.imwrite(output_path, processed_image)\n",
        "        print(f\"Saved processed image to: {output_path}\")\n",
        "        print(\"-\"*50)\n",
        "      else:\n",
        "        print(f\"Could not convert the first page of {resume_name} to an image.\")\n",
        "        print(\"-\"*50)\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing {resume_name}: {e}\")\n",
        "      print(\"-\"*50)\n",
        "\n",
        "\n",
        "print(\"Processing images is completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLW65XkMwMpH",
        "outputId": "ef42acb9-2d52-4c6e-bb3e-23cb3535ce86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing resume: Resume4.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -1.38 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/Resume4.png\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume2.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/Resume2.png\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume1.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.42 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/Resume1.png\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume5.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/Resume5.png\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume3.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.06 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/Resume3.png\n",
            "--------------------------------------------------\n",
            "Processing images is completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text extraction using Tesseract:"
      ],
      "metadata": {
        "id": "2YH7EWVPzPlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "import time\n",
        "\n",
        "input_folder_path = \"/content/processed_images\"\n",
        "output_folder_path = \"/content/tesseract_output\"\n",
        "start_time = time.time()\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(input_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(input_folder_path)[:20], 1):\n",
        "  print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "  image_path = os.path.join(input_folder_path, image_name)\n",
        "  print(\"Extracting text from image..\")\n",
        "  text = pytesseract.image_to_string(Image.open(image_path))\n",
        "  output_path = os.path.join(output_folder_path, image_name.replace(\".png\", \".txt\"))\n",
        "  with open(output_path, \"w\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "  print(f\"Saved extracted text to {output_path}\")\n",
        "  print(\"-\"*50)\n",
        "\n",
        "print(\"Text Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68l4pDBxt4x",
        "outputId": "b3bc5d8a-da2f-4e41-a967-9b4a0fd285f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in folder: 5\n",
            "Processing image 1/5: Resume2.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/Resume2.txt\n",
            "--------------------------------------------------\n",
            "Processing image 2/5: Resume4.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/Resume4.txt\n",
            "--------------------------------------------------\n",
            "Processing image 3/5: Resume1.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/Resume1.txt\n",
            "--------------------------------------------------\n",
            "Processing image 4/5: Resume5.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/Resume5.txt\n",
            "--------------------------------------------------\n",
            "Processing image 5/5: Resume3.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/Resume3.txt\n",
            "--------------------------------------------------\n",
            "Text Extraction Completed.\n",
            "Total time taken: 86.29071760177612 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that all the text is in .txt files, we can pass all the info into an LLM and extract \"information\" from our \"data\""
      ],
      "metadata": {
        "id": "zqJWrXBuz8ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Extract key information from the given resume text.\n",
        "Information to be extracted: Position, skills, summary, work_experience.\n",
        "\n",
        "The text has been extracted from a resume using Tesseract OCR. Use only this text to extract information.\n",
        "Do NOT make up or generate any data. If a field is not present in the text, leave it as a blank string (\"\").\n",
        "\n",
        "For the \"work_experience\" field, summarize the person's experience into a short paragraph highlighting their key roles, achievements, and duration, based only on the extracted text.\n",
        "\n",
        "Always give your response in the following JSON format:\n",
        "\n",
        "{\n",
        "    \"Position\": \"\",\n",
        "    \"skills\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"work_experience\": \"\"\n",
        "}\n",
        "\n",
        "Respond strictly in the specified JSON format without adding any extra commentary or explanation.\n",
        "\n",
        "Here is the extracted text:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tLtC-yKFz7Jy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from PIL import Image\n",
        "import json\n",
        "import time\n",
        "\n",
        "genai_client = genai.Client(api_key=userdata.get('google_api_key'))"
      ],
      "metadata": {
        "id": "u8RX6D1Y012d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "image_folder_path = \"/content/processed_images\"\n",
        "text_folder_path = \"/content/tesseract_output\"\n",
        "output_folder_path = \"/content/json_output\"\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "print(f\"Ensured folder exists: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(image_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(image_folder_path)[:20], 1):\n",
        "    print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "    image_path = os.path.join(image_folder_path, image_name)\n",
        "    print(f\"Loading image: {image_path}\")\n",
        "\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "    # Handle both .png and .jpg\n",
        "    base_name, _ = os.path.splitext(image_name)\n",
        "    text_path = os.path.join(text_folder_path, base_name + \".txt\")\n",
        "\n",
        "    print(f\"Loading extracted text: {text_path}\")\n",
        "    with open(text_path, \"r\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    print(\"Extracting information from image and text..\")\n",
        "\n",
        "    prompt_with_text = prompt + text\n",
        "\n",
        "    contents = [\n",
        "        image,\n",
        "        {\"text\": prompt_with_text}\n",
        "    ]\n",
        "    response = genai_client.models.generate_content(\n",
        "        model='gemini-2.5-flash',\n",
        "        contents=contents\n",
        "    )\n",
        "\n",
        "    # Access the usage_metadata attribute\n",
        "    usage_metadata = response.usage_metadata\n",
        "    print(f\"Input Token Count: {usage_metadata.prompt_token_count}\")\n",
        "    print(f\"Thoughts Token Count: {response.usage_metadata.thoughts_token_count}\")\n",
        "    print(f\"Output Token Count: {usage_metadata.candidates_token_count}\")\n",
        "    print(f\"Total Token Count: {usage_metadata.total_token_count}\")\n",
        "\n",
        "    # ---- Safe response parsing ----\n",
        "    response_text = None\n",
        "    if hasattr(response, \"text\") and response.text:\n",
        "        response_text = response.text\n",
        "    elif hasattr(response, \"candidates\") and response.candidates:\n",
        "        parts = response.candidates[0].content.parts\n",
        "        if parts and hasattr(parts[0], \"text\"):\n",
        "            response_text = parts[0].text\n",
        "\n",
        "    if response_text is None:\n",
        "        print(\"⚠️ No text returned from model. Skipping this file.\")\n",
        "        continue\n",
        "\n",
        "    # Clean and parse JSON safely\n",
        "    response_text = response_text.replace('```json', '').replace('```', '')\n",
        "\n",
        "    try:\n",
        "        extracted_information = json.loads(response_text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"⚠️ Failed to decode JSON for {image_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Save JSON with correct name\n",
        "    output_path = os.path.join(output_folder_path, base_name + \".json\")\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(extracted_information, f, indent=4)\n",
        "\n",
        "    print(f\"Saved extracted information to {output_path}\")\n",
        "    print(\"-\" * 50)\n",
        "    time.sleep(60)\n",
        "\n",
        "print(\"Information Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xRRKT-088H",
        "outputId": "209dec97-f731-4e35-a687-30ad54573377"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensured folder exists: /content/json_output\n",
            "Total images in folder: 5\n",
            "Processing image 1/5: Resume2.png\n",
            "Loading image: /content/processed_images/Resume2.png\n",
            "Loading extracted text: /content/tesseract_output/Resume2.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1236\n",
            "Thoughts Token Count: 1656\n",
            "Output Token Count: 423\n",
            "Total Token Count: 3315\n",
            "Saved extracted information to /content/json_output/Resume2.json\n",
            "--------------------------------------------------\n",
            "Processing image 2/5: Resume4.png\n",
            "Loading image: /content/processed_images/Resume4.png\n",
            "Loading extracted text: /content/tesseract_output/Resume4.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1243\n",
            "Thoughts Token Count: 1762\n",
            "Output Token Count: 300\n",
            "Total Token Count: 3305\n",
            "Saved extracted information to /content/json_output/Resume4.json\n",
            "--------------------------------------------------\n",
            "Processing image 3/5: Resume1.png\n",
            "Loading image: /content/processed_images/Resume1.png\n",
            "Loading extracted text: /content/tesseract_output/Resume1.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1435\n",
            "Thoughts Token Count: 1322\n",
            "Output Token Count: 283\n",
            "Total Token Count: 3040\n",
            "Saved extracted information to /content/json_output/Resume1.json\n",
            "--------------------------------------------------\n",
            "Processing image 4/5: Resume5.png\n",
            "Loading image: /content/processed_images/Resume5.png\n",
            "Loading extracted text: /content/tesseract_output/Resume5.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1401\n",
            "Thoughts Token Count: 2333\n",
            "Output Token Count: 568\n",
            "Total Token Count: 4302\n",
            "Saved extracted information to /content/json_output/Resume5.json\n",
            "--------------------------------------------------\n",
            "Processing image 5/5: Resume3.png\n",
            "Loading image: /content/processed_images/Resume3.png\n",
            "Loading extracted text: /content/tesseract_output/Resume3.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1247\n",
            "Thoughts Token Count: 1567\n",
            "Output Token Count: 459\n",
            "Total Token Count: 3273\n",
            "Saved extracted information to /content/json_output/Resume3.json\n",
            "--------------------------------------------------\n",
            "Information Extraction Completed.\n",
            "Total time taken: 373.682009935379 seconds\n"
          ]
        }
      ]
    }
  ]
}